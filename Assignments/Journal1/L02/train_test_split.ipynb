{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise we will work with the concept of splitting datasets into training and test sets ad dig deeper into the implementations of said concepts, to get a better understading of what is happening in the background of machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Housing data form ยง2 [HOML] \n",
    "\n",
    "We use the housing data from the book, this cell will set everything up for you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing.shape= (20640, 10) \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null float64\n",
      "total_rooms           20640 non-null float64\n",
      "total_bedrooms        20433 non-null float64\n",
      "population            20640 non-null float64\n",
      "households            20640 non-null float64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null float64\n",
      "ocean_proximity       20640 non-null object\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "H.shape= (20640, 10) , type(H)= <class 'numpy.ndarray'>\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    #path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"IGNORING: Saving figure\", fig_id)\n",
    "    #if tight_layout:\n",
    "    #    plt.tight_layout()\n",
    "    #plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"../datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"../datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()\n",
    "\n",
    "import pandas as pd\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "\n",
    "#housing.head()\n",
    "print(\"housing.shape=\",housing.shape,\"\\n\")\n",
    "housing.info()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#housing.hist(bins=50, figsize=(20,15))\n",
    "#save_fig(\"attribute_histogram_plots\")\n",
    "#plt.show()\n",
    "\n",
    "# NOTE: ITMAL, convert Pandas dataframe to numpy array, i.e. matrix\n",
    "#       and use H later instead of housing\n",
    "H = housing.values\n",
    "print('H.shape=',H.shape,\", type(H)=\",type(H))\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our own train-test split function\n",
    "\n",
    "### Qa Create Your Own Split Function\n",
    "\n",
    "create your own split function, that can do the data shuffling (as it is now) or do a simpler split without shuffling.\n",
    "\n",
    "Notice that it would be better to name the function ```my_split_train_test``` to avoid clashing problems later with the Scikit-learn function of the same name. The ```test_ratio``` parameter has also been renamed to ```test_size```. \n",
    "\n",
    "Also note that the split function in [HOML] operates on Pandas data frames, and this will give us a mixup problem later, when we pass the function numpy arrays (matrices).\n",
    "\n",
    "Test that your new split function returns the same number of train and test data no matter if shuffleling is on or off, using the test stub below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qa Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16512 train + 4128 test ..OK\n",
      "16512 train + 4128 test ..OK\n",
      "16512 train + 4128 test ..OK\n",
      "16512 train + 4128 test ..OK\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa...define your my_split_train_test here\n",
    "\n",
    "def my_split_train_test(data, test_size, shuffle=False):\n",
    "    \n",
    "    if shuffle == True:\n",
    "        indices = np.random.permutation(len(data))\n",
    "    \n",
    "    else:\n",
    "        indices = np.arange(len(data))\n",
    "    \n",
    "    \n",
    "    test_set_size = int(len(data) * test_size)\n",
    "    test_indices = indices[len(data)-test_set_size:len(data)]\n",
    "    train_indices = indices[0:len(data)-test_set_size]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "\n",
    "# TEST VECTORS: use the housing panda dataframe or the H numpy object, your choice\n",
    "dat=housing\n",
    "#dat=H\n",
    "\n",
    "def TestSize(train_set, test_set):\n",
    "    # works only for 0.2 split\n",
    "    expected_n_train=16512\n",
    "    expected_n_test=4128\n",
    "    assert len(train_set)==expected_n_train, 'Oh, mismatch in expected train n'\n",
    "    assert len(test_set) ==expected_n_test,  'Oh, mismatch in expected test n'\n",
    "    print(len(train_set), \"train +\", len(test_set), \"test\",\"..OK\")\n",
    "\n",
    "train_set, test_set = my_split_train_test(dat, 0.2, shuffle=False)\n",
    "TestSize(train_set, test_set)\n",
    "\n",
    "train_set, test_set = my_split_train_test(dat, 0.2, shuffle=True)\n",
    "TestSize(train_set, test_set)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(dat, test_size=0.2, shuffle=True, random_state=42)\n",
    "TestSize(train_set, test_set)\n",
    "\n",
    "train_set, test_set = train_test_split(dat, test_size=0.2, shuffle=False)\n",
    "TestSize(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qa Result\n",
    "\n",
    "In the above printouts it's clear that our implementation of the Split_train_test function splits the set in two parts of the same size as the inbuilt version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Why Shuffling\n",
    "\n",
    "Explain why disabling shuffling is a bad idea?\n",
    "\n",
    "Disabling shuffling is a bad idea since you may not have acquired your data randomly. Maybe you've gone from sector to sector which means that taking the first 20% of the dataset might only contain data from one sector, instead of a mix of all the sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc Test and Compare \n",
    "\n",
    "Compare your split function with the one from Scikit-learn, first using the simple X-y data set generated below and then using the housing data via the ```H``` numpy array variable.\n",
    "\n",
    "Splitting the dataset via your split function and the built-in split does not yield a logical true for the comparison\n",
    "\n",
    "```python\n",
    "(y_train == y_train_my).all().all()\n",
    "```\n",
    "\n",
    "Why is it so? Find the exact values in ```H[i,j]``` that are not equal and explain the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= [[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "y= [[0 1 2 3 4]]\n",
      "build-in split: len(train)= 16512 , len(test)= 4128\n",
      "my split:       len(train)= 16512 , len(test)= 4128\n",
      "equal_train= False , equal_test= False\n",
      "build-in split: len(train)= 4 , len(test)= 1\n",
      "my split:       len(train)= 4 , len(test)= 1\n",
      "equal_train= True , equal_test= True\n"
     ]
    }
   ],
   "source": [
    "# Simple data for Qc\n",
    "\n",
    "import numpy as np\n",
    "X1, y = np.arange(10).reshape((5, 2)), np.array([list(range(5))])\n",
    "\n",
    "print(\"X=\",X1)\n",
    "print(\"y=\",y)\n",
    "\n",
    "# TODO: Qc...\n",
    "dataset = pd.DataFrame({'Column1':X1[:,0],'Column2':X1[:,1]})\n",
    "\n",
    "\n",
    "H = dat\n",
    "\n",
    "def test_tts(X):    \n",
    "    # TEST VECTORS: notice that H is not splitted into X-y parts\n",
    "    train, test = train_test_split(X, test_size=0.2, shuffle=False)\n",
    "    print(\"build-in split: len(train)=\",len(train),\", len(test)=\", len(test))\n",
    "\n",
    "    train_my, test_my = my_split_train_test(X, test_size=0.2, shuffle=False)\n",
    "    print(\"my split:       len(train)=\",len(train_my),\", len(test)=\", len(test_my))\n",
    "\n",
    "    # Test for equality here...\n",
    "    assert train.shape==train_my.shape\n",
    "    equal_train=(train.values == train_my.values).all().all()\n",
    "    equal_test =(test.values == test_my.values).all().all()\n",
    "\n",
    "    # TODO: why not equal?\n",
    "    print(\"equal_train=\", equal_train, \", equal_test=\",equal_test)\n",
    "    \n",
    "    \n",
    "test_tts(H)\n",
    "test_tts(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc Results\n",
    "In the above printouts we can see the two sets are equal in value ( not just size ). However changing the splitting ratio might cause some differences with smaller datasets, since one algorithm might round up while the other will round down."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
