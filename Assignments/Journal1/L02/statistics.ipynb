{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2_Statistics - introduction\n",
    "In this exercise we will try to create a mean and variance function where the variance is unbiased. Following that we will look at creating a function for generating an auto covariance matrix.\n",
    "\n",
    "### Mean and Variance\n",
    "\n",
    "The mean and variance (and hence the standard deviation) for a random variable $X$ can for a population of $N$ samples be estimated as\n",
    "\n",
    "$$\n",
    "    \\newcommand\\rem[1]{}\n",
    "    \\rem{ITMAL: CEF def and LaTeX commands, rember: no newlines in defs}\n",
    "    \\newcommand\\eq[2]{#1 &=& #2\\\\}\n",
    "    \\newcommand\\ar[2]{\\begin{array}{#1}#2\\end{array}}\n",
    "    \\newcommand\\ac[2]{\\left[\\ar{#1}{#2}\\right]}\n",
    "    \\newcommand\\st[1]{_{\\mbox{\\scriptsize #1}}}\n",
    "    \\newcommand\\norm[1]{{\\cal L}_{#1}}\n",
    "    \\newcommand\\obs[2]{#1_{\\mbox{\\scriptsize obs}}^{\\left(#2\\right)}}\n",
    "    \\newcommand\\diff[1]{\\mbox{d}#1}\n",
    "    \\newcommand\\pown[1]{^{(#1)}}\n",
    "    \\def\\pownn{\\pown{n}}\n",
    "    \\def\\powni{\\pown{i}}\n",
    "    \\def\\powtest{\\pown{\\mbox{\\scriptsize test}}}\n",
    "    \\def\\powtrain{\\pown{\\mbox{\\scriptsize train}}}\n",
    "    \\def\\bX{\\mathbf{X}}\n",
    "    \\def\\bZ{\\mathbf{Z}}\n",
    "    \\def\\bx{\\mathbf{x}}\n",
    "    \\def\\bw{\\mathbf{w}}\n",
    "    \\def\\by{\\mathbf{y}}\n",
    "    \\def\\bz{\\mathbf{z}}\n",
    "    \\def\\btheta{{\\boldsymbol\\theta}}\n",
    "    \\def\\half{\\frac{1}{2}}\n",
    "    \\begin{array}{rl}\n",
    "        E[X] &= \\frac{1}{N} \\sum_{i=1}^N X_i\\\\\n",
    "             &= \\mu_X\\\\\n",
    "        V[X] &= E[(X_i -E[X])(X_i -E[X])] \\\\\n",
    "             &= E[X_i X_i] - E[X]^2\\\\\n",
    "             &= \\left( \\frac{1}{N} \\sum_{i=1}^N X_i X_i \\right) - \\mu_X^2\\\\\n",
    "             &= \\sigma_X^2\\\\\n",
    "        \\sigma & = \\sqrt{V}\n",
    "    \\end{array}\n",
    "$$\n",
    "\n",
    "When using the factor $1/(N-1)$, $\\hat V$ is said to be the best unbiased estimator, when it is $1/N$ it will be biased, both assuming an underlying normal distribution. \n",
    "\n",
    "### Auto covariance in Matrix Notation\n",
    "\n",
    "Now let's goto full matrix notation for the covariance. For a data matrix $\\bX$  \n",
    "\n",
    "$$\n",
    "    \\bX = \\ac{cccc}{\n",
    "        x_1^{(1)} & x_2^{(1)} & \\cdots & x_d^{(1)} \\\\\n",
    "        x_1^{(2)} & x_2^{(2)} & \\cdots & x_d^{(2)}\\\\\n",
    "        \\vdots \\\\\n",
    "        x_1^{(n)} & x_2^{(n)} & \\cdots & x_d^{(n)}\\\\\n",
    "    }\n",
    "$$\n",
    "\n",
    "the previous one-dimensional random variable $X$ can now be seen as a $d$-dimensional vector $\\bx\\powni$, that is one of the data rows in the full data matrix\n",
    "\n",
    "$$\n",
    "    X_i \\to \\bx\\powni = \\left[  x_1\\powni~~ x_2\\powni~~ \\cdots~~ x_d\\powni\\right]^T\n",
    "$$\n",
    "\n",
    "The (biased) auto‚Äìcovariance matrix can be estimated as\n",
    "\n",
    "$$\n",
    "  \\ar{rl}{\n",
    "            E[\\bX] &= \\mu_\\bX \\\\\n",
    "                   &= \\frac{1}{n} \\sum_{i=1}^{n} \\bx\\powni \\\\ \\\\\n",
    "       \\Sigma(\\bX) &= \\mbox{cov}(\\bX,\\bX) \\\\\n",
    "                   &= \\frac{1}{n} \\sum_{i=1}^{n} \\bx\\powni\\bx^{(i)T} - \\mu_\\bX\\mu_\\bX^T \n",
    "   }\n",
    "   \\rem{\n",
    "     \\ar{ll}{\n",
    "        \\Sigma(\\bX) &= \\mbox{cov}(\\bX,\\bX)\\\\\n",
    "          &= E\\left[(\\bX-\\mu_\\bX)(\\bX-\\mu_\\bX)^T \\right]\\\\\n",
    "          &= E\\left[ \\bX\\bX^T \\right] - E[\\bX]E[\\bX]^T\\\\\n",
    "          &= E\\left[ \\bX\\bX^T \\right] - \\mu_\\bX\\mu_\\bX^T\n",
    "      }\n",
    "   }\n",
    "$$\n",
    "\n",
    "## Implementation \n",
    "The assignment description will more or less come as given before each task.\n",
    "\n",
    "#### Qa Creating a mean and variance function for some input data\n",
    "\n",
    "Your python function should be named ```MeanAndVariance()```, it takes a vector as input parameter, and returns TWO parameters, namely mean and variance. \n",
    "\n",
    "Python allows for return of zero, one, or more parameters from a function, without having to place, say two output parameters in a tuple, like in C++ ```return make_pair<float,float>(mean, variance)```.\n",
    "\n",
    "Test it via the ```y``` input and test-vectors below, go for the biased variance estimator at first.\n",
    "\n",
    "Then extend it to handle both biased and un-biased estimators, create your own test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected_m = 2.5 , m = 2.5 , difference = 0.0\n",
      "Expected_v_biased= 1.25 , v= 1.6666666666666679\n",
      "\n",
      "Difference in biased and unbiased variance = 0.41666666666666785\n",
      "\n",
      "Difference in expected and calculated ubiased variance = 1.1102230246251565e-15\n"
     ]
    }
   ],
   "source": [
    "# Qa\n",
    "import numpy as np\n",
    "\n",
    "def MeanAndVariance(x, bias = 0):    \n",
    "    # implementing the mean and variance function, which returns the Variance.\n",
    "    # Biased or unbiased variance can be chosen by seeting param 'bias' to 1 for unbiased, 0 for biased.\n",
    "    # Thus the function will per default be biased.\n",
    "    n = len(x)\n",
    "    m1 = (1/(n))*sum(x)\n",
    "    \n",
    "    v1 = ( ( 1/(n-bias) )*( sum( pow(x,2) ) ) ) - ( ( n/(n-bias) )*pow(m1,2) )\n",
    "    \n",
    "    return m1, v1\n",
    "\n",
    "# Test-case - testing the mean and varianve calculation.\n",
    "y = np.array([1,2,3,4])\n",
    "m, v = MeanAndVariance(y, 1)\n",
    "\n",
    "expected_v_unbiased = 1.6666666666666667 # factor 1/(n-1)\n",
    "\n",
    "print(\"Expected_m =\", np.mean(y), \", m =\",m,\", difference =\", m-np.mean(y))\n",
    "\n",
    "print(\"Expected_v_biased=\", np.var(y), \", v=\", v)\n",
    "\n",
    "print(\"\\nDifference in biased and unbiased variance =\", v-np.var(y))\n",
    "\n",
    "print(\"\\nDifference in expected and calculated ubiased variance =\", v-expected_v_unbiased)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Qb Create a function that generates the auto-covariance matrix $\\Sigma(\\bX)$.\n",
    "\n",
    "At this task we are creating a function that can genereate an auto-covariance matrix.\n",
    "\n",
    "`numpy.cov` will only serve as a test stub, to check that we got the right calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected biased covariance matrix\n",
      "[[ 6.42908842 -6.7827325 ]\n",
      " [-6.7827325   8.30601927]]\n",
      "\n",
      "Calculated biased covariance matrix\n",
      "[[ 6.42908842 -6.7827325 ]\n",
      " [-6.7827325   8.30601927]]\n",
      "\n",
      "Expected unbiased covariance matrix\n",
      "[[ 6.5602943  -6.92115562]\n",
      " [-6.92115562  8.47552987]]\n",
      "\n",
      "Calculated unbiased covariance matrix\n",
      "[[ 6.5602943  -6.92115562]\n",
      " [-6.92115562  8.47552987]]\n"
     ]
    }
   ],
   "source": [
    "#Qb\n",
    "import numpy as np\n",
    "\n",
    "def covar(x, y, bias = 0):\n",
    "    #bias is set to 0 for biased variance and 1 for unbiased.\n",
    "    n = len(x)\n",
    "    if(n != len(y)):\n",
    "        print(\"Err, different lengths.\")\n",
    "        return 0\n",
    "        \n",
    "    mx = (1/(n))*sum(x)\n",
    "    my = (1/(n))*sum(y)\n",
    "    \n",
    "    cv1 = (1/(n-bias))*sum((x-mx)*(y-my))\n",
    "    \n",
    "    return cv1\n",
    "\n",
    "def covar_mat(X, bias = 0):\n",
    "    #bias is set to 0 for biased variance matrix and 1 for unbiased.\n",
    "    mat = np.array([[covar(X[0], X[0], bias),  \\\n",
    "                     covar(X[0], X[1], bias)], \\\n",
    "                    [covar(X[1], X[0], bias),  \\\n",
    "                     covar(X[1], X[1], bias)]])\n",
    "    return mat\n",
    "\n",
    "#Get a normal distributed x and y vector with mean = 0 and stanard deviation = 1\n",
    "N = 50\n",
    "x = np.random.normal(0, 1, N)\n",
    "y = np.random.normal(0, 1, N)\n",
    "\n",
    "X = np.vstack((x, y)).T\n",
    "\n",
    "# we rotate the matrix\n",
    "theta = 0.77*np.pi\n",
    "cos, sin = np.cos(theta), np.sin(theta)\n",
    "rot = np.array([[cos, -sin], \\\n",
    "                [sin, cos]])\n",
    "\n",
    "# we scale the matrix\n",
    "s_x = 0.7\n",
    "s_y = 3.4\n",
    "scale = np.array([[s_x, 0], \\\n",
    "                  [0, s_y]])\n",
    "\n",
    "# Transformation matrix\n",
    "T_mat = scale.dot(rot)\n",
    "\n",
    "# Apply transformation matrix to X\n",
    "Y = X.dot(T_mat)\n",
    "\n",
    "cv_mat_biased = covar_mat(Y.T, 0)\n",
    "cv_mat_unbiased = covar_mat(Y.T, 1)\n",
    "expected_cv_biased = np.cov(Y.T, rowvar=True, bias=True)\n",
    "expected_cv_unbiased = np.cov(Y.T, rowvar=True, bias=False)\n",
    "\n",
    "#printing the results.\n",
    "print(\"Expected biased covariance matrix\")\n",
    "print(expected_cv_biased)\n",
    "\n",
    "print(\"\\nCalculated biased covariance matrix\")\n",
    "print(cv_mat_biased)\n",
    "\n",
    "print(\"\\nExpected unbiased covariance matrix\")\n",
    "print(expected_cv_unbiased)\n",
    "\n",
    "print(\"\\nCalculated unbiased covariance matrix\")\n",
    "print(cv_mat_unbiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Conclusion.\n",
    "\n",
    "From the MeanAndVariance function a small difference in the expected unbiased variance and the calculated unbiased variance was detected, but such a small difference it would only make sense to be some form of error in rounding the number.\n",
    "\n",
    "From the covariance function some good and expected results was found which is seen just above this section. \n",
    "It can be seen that the diagonal elements Œ£ùëñùëñ represents the variance for x and y respectivly on spots 0,0 and 1,1. Where the off diagonal elements Œ£ùëñùëó  for ùëñ‚â†ùëó then represents the co-varaince between x and y on spots 0,1 and 1,0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
